{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26aff933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'x': tensor([ 30, 410,  10,  40]), 'y': tensor([ 9, 14,  7,  8])}\n",
      "1 {'x': tensor([40, 80, 90, 50]), 'y': tensor([ 6,  3,  4, 44])}\n",
      "2 {'x': tensor([70]), 'y': tensor([2])}\n"
     ]
    }
   ],
   "source": [
    "from typing import Union, Optional, List, Tuple\n",
    "\n",
    "class MoDataSet():\n",
    "    def __init__(self,\n",
    "                 X_data_or_dir:Union[str,list],\n",
    "                 Y_data_or_dir:Union[str,list],\n",
    "                 root:str='',\n",
    "                 x_format:str='*',\n",
    "                 y_format:str='*',\n",
    "                 transform_dict:Optional[Union[dict,list]]={'train':{},'test':{},'eval':{}},\n",
    "                 test_size:float=0.2,\n",
    "                 eval_size:float=0, **arg):\n",
    "        from glob import glob\n",
    "        from os.path import join as path_join\n",
    "        from os.path import basename as path_basename\n",
    "        from os.path import splitext as path_splitext\n",
    "        from torch.utils.data import Dataset\n",
    "        from torch.utils.data import DataLoader\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        from numpy import load as np_load\n",
    "\n",
    "        class DataByPath(Dataset):\n",
    "            def __init__(self, x_paths, y_paths, transforms={}):\n",
    "                self.x_paths = x_paths\n",
    "                self.y_paths = y_paths\n",
    "                self.transforms = transforms\n",
    "\n",
    "            def __getitem__(self, index):\n",
    "                data_x = np_load(self.x_paths[index])\n",
    "                data_y = np_load(self.y_paths[index])\n",
    "                if 'x' in self.transforms:\n",
    "                    data_x = self.transforms['x'](data_x)\n",
    "                if 'y' in self.transforms:\n",
    "                    data_y = self.transforms['y'](data_y)\n",
    "                return {'x': data_x, 'y': data_y}\n",
    "                # img = Image.open()\n",
    "\n",
    "            def __len__(self):\n",
    "                return len(self.y_paths)\n",
    "\n",
    "            def to_loader(self, **args):\n",
    "                return DataLoader(self, **args)\n",
    "        class DataAccess(Dataset):\n",
    "            def __init__(self, X, Y, transforms={}):\n",
    "                self.X =X\n",
    "                self.Y = Y\n",
    "                self.transforms = transforms\n",
    "\n",
    "            def __getitem__(self, index):\n",
    "                data_x = self.X[index]\n",
    "                data_y = self.Y[index]\n",
    "                if 'x' in self.transforms:\n",
    "                    data_x = self.transforms['x'](data_x)\n",
    "                if 'y' in self.transforms:\n",
    "                    data_y = self.transforms['y'](data_y)\n",
    "                return {'x': data_x, 'y': data_y}\n",
    "                # img = Image.open()\n",
    "\n",
    "            def __len__(self):\n",
    "                return len(self.Y)\n",
    "\n",
    "            def to_loader(self, **args):\n",
    "                return DataLoader(self, **args)\n",
    "\n",
    "        self.TrainDataset,self.TestDataset,self.EvalDataset=None,None,None\n",
    "        if isinstance(transform_dict,list):\n",
    "            transform_dict={aset:{avar:transform_dict for avar in ['x','y']} for aset in ['train','test','eval']}\n",
    "        if x_format[0]!='.':\n",
    "            x_format='.'+x_format\n",
    "        if y_format[0]!='.':\n",
    "            y_format='.'+y_format\n",
    "        if isinstance(X_data_or_dir,str):\n",
    "            assert isinstance(Y_data_or_dir,str),'the type of input X and Y must be same'\n",
    "            X_train = glob(path_join(root,X_data_or_dir,'*'+x_format))\n",
    "            Y_train = [path_join(root,Y_data_or_dir, path_splitext(path_basename(x) ) [0]) + y_format for x in X_train]\n",
    "        else:\n",
    "            X_train=X_data_or_dir\n",
    "            Y_train=Y_data_or_dir\n",
    "\n",
    "        if test_size>0:\n",
    "            X_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, test_size=test_size,**arg)  # random_state=0,stratify=Y\n",
    "        if eval_size>0:\n",
    "            X_train, X_eval, Y_train, Y_eval = train_test_split(X_train, Y_train, test_size=eval_size,**arg)  # random_state=0,stratify=Y\n",
    "        if isinstance(X_data_or_dir,str):\n",
    "            self.TrainDataset=DataByPath(X_train,Y_train,transforms=transform_dict['train'])\n",
    "            if test_size>0:\n",
    "                self.TestDataset = DataByPath(X_test, Y_test, transforms=transform_dict['test'])\n",
    "            if eval_size>0:\n",
    "                self.EvalDataset = DataByPath(X_eval, Y_eval, transforms=transform_dict['eval'])\n",
    "        else:\n",
    "            self.TrainDataset = DataAccess(X_train, Y_train, transforms=transform_dict['train'])\n",
    "            if test_size > 0:\n",
    "                self.TestDataset = DataAccess(X_test, Y_test, transforms=transform_dict['test'])\n",
    "            if eval_size > 0:\n",
    "                self.EvalDataset = DataAccess(X_eval, Y_eval, transforms=transform_dict['eval'])\n",
    "\n",
    "\n",
    "mm=MoDataSet(X_data_or_dir=[10,20,30,40,70,80,90,110,40,50,60,410],Y_data_or_dir=[7,8,9,6,2,3,4,7,8,44,12,14])\n",
    "for id,it in enumerate(mm.TrainDataset.to_loader(batch_size=4)):\n",
    "    print(id,it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94ab62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Compose:\n",
    "    \"\"\"Composes several transforms together. This transform does not support torchscript.\n",
    "    Please, see the note below.\n",
    "    \n",
    "    Args:\n",
    "        transforms (list of ``Transform`` objects): list of transforms to compose.\n",
    "        \n",
    "    Example:\n",
    "        >>> transforms.Compose([\n",
    "        >>>     transforms.CenterCrop(10),\n",
    "        >>>     transforms.ToTensor(),\n",
    "        >>> ])\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, img):\n",
    "        for t in self.transforms:\n",
    "            img = t(img)\n",
    "        return img\n",
    "\n",
    "    def __repr__(self):\n",
    "        format_string = self.__class__.__name__ + '('\n",
    "        for t in self.transforms:\n",
    "            format_string += '\\n'\n",
    "            format_string += '    {0}'.format(t)\n",
    "        format_string += '\\n)'\n",
    "        return format_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1286db01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': {'x': ['it', 'is'], 'y': ['it', 'is']}, 'test': {'x': ['it', 'is'], 'y': ['it', 'is']}, 'eval': {'x': ['it', 'is'], 'y': ['it', 'is']}}\n"
     ]
    }
   ],
   "source": [
    "transform_dict=['it','is']\n",
    "transform_dict={aset:{avar:transform_dict for avar in ['x','y']} for aset in ['train','test','eval']}\n",
    "print(transform_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
