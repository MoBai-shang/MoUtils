{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 结果可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')  #风格设置近似R这种的ggplot库\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "def drawpearson(data):\n",
    "    colormap = plt.cm.viridis\n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.title('Pearson Correlation of Features', y=1.05, size=15)\n",
    "    sns.heatmap(\n",
    "        data[data.columns].corr(),linewidths=0.1,vmax=1.0, square=True, cmap=colormap, linecolor='white', annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## 特征选择"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 皮尔逊相关性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          n    r       CI95%  p-val BF10  power\n",
      "pearson  15  1.0  [1.0, 1.0]    0.0  inf      1\n",
      "          n         r         CI95%     p-val      BF10     power\n",
      "pearson  15  0.910622  [0.75, 0.97]  0.000002  6952.199  0.999718\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pingouin as pg\n",
    "\n",
    "np.random.seed(123)\n",
    "mean, cov, n = [4, 5], [(1, .6), (.6, 1)], 30\n",
    "x, y = np.random.multivariate_normal(mean, cov, n).T\n",
    "x=np.arange(15)\n",
    "y=x*3\n",
    "print(pg.corr(x, y))\n",
    "x=np.arange(15)\n",
    "y=x**3\n",
    "print(pg.corr(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 鲁棒检验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>r</th>\n",
       "      <th>CI95%</th>\n",
       "      <th>p-val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pearson</th>\n",
       "      <td>30</td>\n",
       "      <td>0.568</td>\n",
       "      <td>[0.25, 0.77]</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          n      r         CI95%  p-val\n",
       "pearson  30  0.568  [0.25, 0.77]  0.001"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#添加一个异常值\n",
    "x[5] = 18\n",
    "#使用Shepherd's pi correlation\n",
    "pg.corr(x, y, method=\"shepherd\")\n",
    "import pingouin as pg\n",
    "df = pg.read_dataset('partial_corr')\n",
    "pg.partial_corr(data=df, x='x', y='y', covar='cv1').round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 离散变量自相关性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.         -0.0972973   0.06216216 -0.07567568 -0.38918919]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\stattools.py:657: FutureWarning: The default number of lags is changing from 40 tomin(int(10 * np.log10(nobs)), nobs - 1) after 0.12is released. Set the number of lags to an integer to  silence this warning.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\stattools.py:667: FutureWarning: fft=True will become the default after the release of the 0.12 release of statsmodels. To suppress this warning, explicitly set fft=False.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.tsa.api as smt\n",
    "\n",
    "\n",
    "time_series = [2, 3, 4, 3, 7]\n",
    "acf = smt.stattools.acf(time_series)\n",
    "print(acf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 线性互相关"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len a=8,len v=6\n",
      "[103 129 155] 3\n",
      "[103 129 155]\n",
      "[ 32  53  77 103 129 155 127 102] 8\n",
      "[ 32  53  77 103 129 155 127 102]\n",
      "[  6  17  32  53  77 103 129 155 127 102  81  38  16] 13\n",
      "[  6  17  32  53  77 103 129 155 127 102  81  38  16]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "a=[1,2,3,4,5,6,7,8]\n",
    "v=[2,3,6,4,5,6]\n",
    "\n",
    "'''\n",
    "mode = ‘valid’：只返回有效的那一部分相关数据，共M-N+1个；\n",
    "mode = ‘same’：只返回与等长的那一部分相关数据，共N个；\n",
    "mode = ‘full’：返回全部相关数据，共M+N-1个。\n",
    "'''\n",
    "#以下两个方式调用参数完全相同。在调用时有三种模式可供选择，它们计算的内容是相同的，但是返回值长度各不相同：\n",
    "print('len a=%d,len v=%d'%(len(a),len(v)))\n",
    "for mode in ['valid','same','full']:\n",
    "    print(np.correlate(a, v, mode),len(np.correlate(a, v, mode)))\n",
    "    print(signal.correlate(a, v, mode))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SequentialFeatureSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "\n",
      "[2021-11-21 12:34:48] Features: 1/4 -- score: 0.8629032258064516[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    0.0s finished\n",
      "\n",
      "[2021-11-21 12:34:48] Features: 2/4 -- score: 0.9596774193548387[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "\n",
      "[2021-11-21 12:34:48] Features: 3/4 -- score: 0.9919354838709677[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "\n",
      "[2021-11-21 12:34:48] Features: 4/4 -- score: 0.9838709677419355"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: {'feature_idx': (6,),\n",
       "  'cv_scores': array([0.86290323]),\n",
       "  'avg_score': 0.8629032258064516,\n",
       "  'feature_names': ('6',)},\n",
       " 2: {'feature_idx': (6, 9),\n",
       "  'cv_scores': array([0.95967742]),\n",
       "  'avg_score': 0.9596774193548387,\n",
       "  'feature_names': ('6', '9')},\n",
       " 3: {'feature_idx': (6, 9, 11),\n",
       "  'cv_scores': array([0.99193548]),\n",
       "  'avg_score': 0.9919354838709677,\n",
       "  'feature_names': ('6', '9', '11')},\n",
       " 4: {'feature_idx': (6, 8, 9, 11),\n",
       "  'cv_scores': array([0.98387097]),\n",
       "  'avg_score': 0.9838709677419355,\n",
       "  'feature_names': ('6', '8', '9', '11')}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from mlxtend.data import wine_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X, y = wine_data()\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, \n",
    "                                                   stratify=y,\n",
    "                                                   test_size=0.3,\n",
    "                                                   random_state=1)\n",
    "std = StandardScaler()\n",
    "X_train_std = std.fit_transform(X_train)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)    # ①\n",
    "sfs = SFS(estimator=knn,     # ②\n",
    "           k_features=4,\n",
    "           forward=True, \n",
    "           floating=False, \n",
    "           verbose=2,\n",
    "           scoring='accuracy',\n",
    "           cv=0)\n",
    "sfs.fit(X_train_std, y_train)\n",
    "sfs.subsets_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 低方差滤波器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LowVarianceFilter(data,feature_column,n_components=-1):\n",
    "    df=data[feature_column]\n",
    "    #归一化\n",
    "    df=df.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x))) \n",
    "    var=df.var()#/np.mean(df)\n",
    "    #print(var)\n",
    "    sort_var=sorted(enumerate(var),key=lambda x:x[1],reverse=True)\n",
    "    cols=[feature_column[it[0]] for it in sort_var][:n_components]\n",
    "    print(var[cols])\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用VarianceThreshold类进行方差过滤\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "def LowVarianceFilter2(data,feature_column,score_column,n_components=-1):\n",
    "    #要生成这个类的对象，就需要一个参数，就是最小方差的阈值，我们先设置为1，然后调用它的transform方法进行特征值的过滤\n",
    "    variancethreshold=VarianceThreshold(threshold=300)\n",
    "    variancethreshold.fit_transform(data[feature_column],data[score_column])\n",
    "    #使用get_support方法，可以得到选择特征列的序号，然后根据这个序号在原始数据中把对应的列名选择出来即可\n",
    "    cols=feature_column[variancethreshold.get_support()].tolist()\n",
    "    print(cols)\n",
    "    return cols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 高相关性滤波器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#高相关滤波（High Correlation filter）,过滤指标，传入数据喝需要计算的列，如果两个变量之间是高度相关的，这意味着它们具有相似的趋势并且可能携带类似的信息。\n",
    "def HighCorrelationFilter(data,feature_column,n_components=-1):\n",
    "    #计算每个指标的方差\n",
    "    corr = data.loc[:, feature_column].corr()\n",
    "    #print(corr)\n",
    "    corr=corr**2\n",
    "    cor_dict={}\n",
    "    for it in feature_column:\n",
    "        cor_dict[it]=0\n",
    "    for i in feature_column:\n",
    "        for j in feature_column:\n",
    "            cor_dict[i]+=corr[i][j]\n",
    "    sort_cor= sorted(cor_dict.items(),key=lambda x:x[1],reverse=False)[:n_components]\n",
    "    cols=[it[0] for it in sort_cor]\n",
    "    print(cols)\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 相关系数法\n",
    "\n",
    "先计算各个特征对目标值的相关系数，选择更加相关的特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SelectKBest类，通过回归的方法，以及要选择多少个特征值，新建一个 SelectKBest对象，\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "def SelectBestFeature(data,feature_column,score_column,n_components=-1):\n",
    "    if n_components==-1:\n",
    "        n_components=len(feature_column)\n",
    "    selectKBest = SelectKBest(\n",
    "        f_regression,k=n_components\n",
    "    )\n",
    "    #接着，把自变量选择出来，然后调用fit_transform方法，把自变量和因变量传入，即可选出相关度最高的变量。\n",
    "    bestFeature =selectKBest.fit_transform(\n",
    "        data[feature_column],\n",
    "        data[score_column]\n",
    "    )\n",
    "    #我们想要知道选出的自变量的名字，使用get_support方法即可得到相应的列名\n",
    "    cols=feature_column[selectKBest.get_support()].tolist()\n",
    "    print(cols)\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型选择法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "def SelectFeatureFromModel(data,feature_column,score_column):\n",
    "    #lrModel =LinearRegression()\n",
    "    lrModel=GradientBoostingClassifier(n_estimators=200)\n",
    "    selectFromModel = SelectFromModel(lrModel)\n",
    "    selectFromModel.fit_transform(data[feature_column],data[score_column])\n",
    "    #我们想要知道选出的自变量的名字，使用get_support方法即可得到相应的列名\n",
    "    cols=feature_column[selectFromModel.get_support()].tolist()\n",
    "    print(cols)\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机森林\n",
    "是一个广泛使用的特征选择算法，该算法可以计算出每个特征变量的重要性，从而我们可以舍弃重要性低的变量达到将为的目的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "def GetFeatureByRandomForest(data,feature_column,score_column,n_components=-1):\n",
    "    model = RandomForestClassifier(random_state=1, max_depth=10)\n",
    "    #train=pd.get_dummies(train)\n",
    "    #print(train)\n",
    "    model.fit(data[feature_column],data[score_column])\n",
    "    #plot the feature importance graph\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances) \n",
    "    plt.title('Feature Importances')\n",
    "    plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "    plt.yticks(range(len(indices)), [feature_column[i] for i in indices])\n",
    "    plt.xlabel('Relative Importance')\n",
    "    plt.show()\n",
    "    # use the SelectFromModel to selects the features \n",
    "    feature = SelectFromModel(model)\n",
    "    fit = feature.fit_transform(data[feature_column],data[score_column])\n",
    "    column_num = fit.shape[1]\n",
    "    #np.argsort(x) #按升序排列 np.argsort(-x) #按降序排列 取索引\n",
    "    indices = np.argsort(-importances)\n",
    "    cols=feature_column[indices][:n_components].tolist()\n",
    "    auto_select__columns = []\n",
    "    for c in range(column_num):\n",
    "        auto_select__columns.append(feature_column[indices[c]])\n",
    "    print(cols)\n",
    "    print(auto_select__columns)\n",
    "    return cols,auto_select__columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 反向特征消除\n",
    "先将所有变量用于模型训练，然后在分别去掉其中一个变量再进行训练，如果训练的效果好则舍弃该变量。该方法一般用于构造线性回归或者Logistic回归。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入RFE方法和线性回归基模型\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression,Ridge,Lasso\n",
    "def BackwardFeatureSelection(data,feature_column,score_column,n_components=-1):\n",
    "    if n_components==-1:\n",
    "        n_components=len(feature_column)\n",
    "    lreg = Ridge(alpha=100000, fit_intercept=True, normalize=True,\n",
    "               copy_X=True, max_iter=1500, tol=1e-4, solver='auto')\n",
    "    #lreg = LinearRegression()  # 选择lin线性回归为基模型\n",
    "    rfe = RFE(\n",
    "        #estimator=LinearRegression(normalize=True),\n",
    "        #estimator=Lasso(normalize=True),\n",
    "        estimator=lreg,\n",
    "        #n_features_to_select=28  # 选区特征数\n",
    "        n_features_to_select = n_components  # 选区特征数\n",
    "    )\n",
    "    # fit 方法训练选择特征属性\n",
    "    #sFeature = rfe.fit_transform(feature, data[\"RON损失（不是变量）\"])\n",
    "    sFeature = rfe.fit_transform(data[feature_column], data[score_column])\n",
    "\n",
    "    # 2d matrix: clonum: opt Value, row:\n",
    "    FRMatrix = sFeature.tolist()\n",
    "    print(rfe.get_support(), \"type is: \", type(rfe.get_support()))\n",
    "    chosenFlags = rfe.get_support().tolist()\n",
    "    #print(chosenFlags)\n",
    "    cols=feature_column[rfe.get_support()].tolist()\n",
    "    print(cols) #查看满足条件的属性\n",
    "    return cols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 前向特征选择（Forward Feature Selection）\n",
    "前向特征选择其实就是反向特征消除的相反过程，即找到能改善模型性能的最佳特征，而不是删除弱影响特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_regression\n",
    "# 前向特征选择（Forward Feature Selection）前向特征选择其实就是反向特征消除的相反过程，即找到能改善模型性能的最佳特征\n",
    "def ForwardFeatureSelection(data,index_column,score_column,n_components=-1):\n",
    "    df = data.loc[:, index_column]\n",
    "    score_df = data.loc[:, score_column]\n",
    "    #F值越大，p值越小越好，这里我们选择F值大于10的变量\n",
    "    ffs = f_regression(df,score_df )\n",
    "    ffs_dict={}\n",
    "    new_columns = []\n",
    "    for i in range(len(df.columns)):\n",
    "        ffs_dict[df.columns[i]]=ffs[0][i]\n",
    "    ffs_result=sorted(ffs_dict.items(),key=lambda x:x[1],reverse=True)[:n_components]\n",
    "    cols=[it[0] for it in ffs_result]\n",
    "    print(cols)\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "># 数据降维 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 因子分析（Factor Analysis）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FactorAnalysis\n",
    "# 因子分析（Factor Analysis），返回降维后的新数据\n",
    "def FactorAnalysisFeatureSelection(data,index_column,n_components=3):\n",
    "    df = data.loc[:, index_column]\n",
    "    fa = FactorAnalysis(n_components=n_components)  # 指定7个因子作为新变量\n",
    "    fa.fit(df)\n",
    "    tran_x = fa.transform(df)\n",
    "    factor_columns = []\n",
    "    for index in range(n_components):\n",
    "        tmp = \"factor\" + str(index + 1)\n",
    "        factor_columns.append(tmp)\n",
    "    tran_df = pd.DataFrame(tran_x, columns=factor_columns)\n",
    "    return tran_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于核函数的非线性降维方法：\n",
    "### 核 PCA（Kernel PCA）\n",
    "KPCA其实是先采用增加多项式等方式提高了数据的维度，再使用标准PCA，寻找一个可以进行有效分类的方向进行投影降维。\n",
    "\n",
    "from sklearn.decomposition import KernelPCA rbf_pca=KernelPCA(n_components=2,kernel='rbf',gamma=0.04) X_reduced=rbf_pca.fit_transform(X)\n",
    "\n",
    "调整超参数： 由于 kPCA 是无监督学习算法，因此没有明显的性能指标可以帮助您选择最佳的核方法和超参数值。但是，降维通常是监督学习任务（例如分类）的准备步骤.\n",
    "\n",
    "引入模型，通过最优化模型表现调参 使用 kPCA 将维度降至低维维，然后应用 Logistic 回归进行分类。然后使用 Grid SearchCV 为 kPCA 找到最佳的核和 gamma 值，以便在最后获得最佳的分类准确性.（引入模型，以最优化模型表现调参）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import KernelPCA\n",
    "print('start...')\n",
    "clf = Pipeline([\n",
    "        ('ss', StandardScaler()),\n",
    "        (\"kpca\", KernelPCA(n_components=num_of_col)),\n",
    "        (\"log_reg\",GaussianNB())\n",
    "        ])\n",
    "    #LogisticRegression(solver=\"lbfgs\",multi_class=\"auto\",max_iter=5000)\n",
    "param_grid = [{\"kpca__gamma\": np.linspace(0.1,0.2, 10),\"kpca__kernel\": [\"rbf\",\"poly\", \"sigmoid\"]}]\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5)\n",
    "grid_search.fit(X,Y)\n",
    "\n",
    "#通过调用 best_params_ 变量来查看使模型效果最好的核和超参数：\n",
    "best_par=grid_search.best_params_\n",
    "print(best_par)\n",
    "\n",
    "from sklearn.decomposition import KernelPCA\n",
    "print('start...')\n",
    "#best_par={'kpca__gamma': 0.09444444444444444, 'kpca__kernel': 'sigmoid'}\n",
    "rbf_pca=KernelPCA(n_components=num_of_col,kernel=best_par['kpca__kernel'],gamma=best_par['kpca__gamma'])\n",
    "new_X=rbf_pca.fit_transform(X)\n",
    "\n",
    "new_df=pd.DataFrame(np.c_[new_X,Y],columns=col_name)\n",
    "writer = pd.ExcelWriter(os.path.join(drd_path,'data_KPCA.xlsx'))\n",
    "new_df.to_excel(writer,'Sheet1',index=False)\n",
    "writer.save()\n",
    "print('generated data:',new_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated data: (4141, 1)\n",
      "[0.87377329]\n",
      "[22721.88191916]\n",
      "9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Component-wise and Cumulative Explained Variance')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "#PCA数据降维\n",
    "pca = PCA(n_components=num_of_col)  # n_components：目标维度\n",
    "pca.fit(X)\n",
    "#降维后数据\n",
    "new_X = pca.fit_transform(X)\n",
    "\n",
    "new_df=pd.DataFrame(np.c_[new_X,Y],columns=col_name)\n",
    "writer = pd.ExcelWriter(os.path.join(drd_path,'data_PCA.xlsx'))\n",
    "new_df.to_excel(writer,'Sheet1',index=False)\n",
    "writer.save()\n",
    "print('generated data:',new_X.shape)\n",
    "\n",
    "print(pca.explained_variance_ratio_)  #输出贡献率\n",
    "print(pca.explained_variance_)  # 输出方差值，方差值越大，表明越重要\n",
    "print(pca.n_features_)\n",
    "#print(pca.n_features_in_)\n",
    "plt.plot(range(num_of_col), pca.explained_variance_ratio_)\n",
    "plt.plot(range(num_of_col), np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.title(\"Component-wise and Cumulative Explained Variance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性降维方法：\n",
    "### LDA降维（线性判别分析）\n",
    "是有监督的线性分类器： fit()\n",
    "\n",
    "LDA与PCA最大区别：最大化类间样本的方差，最小化类内样本的方差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated data: (4141, 1)\n",
      "[0.83598521]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "lda = LDA( n_components=num_of_col).fit(X, Y)\n",
    "new_X = lda.transform(X)\n",
    "\n",
    "new_df=pd.DataFrame(np.c_[new_X,Y],columns=col_name)\n",
    "writer = pd.ExcelWriter(os.path.join(drd_path,'data_LDA.xlsx'))\n",
    "new_df.to_excel(writer,'Sheet1',index=False)\n",
    "writer.save()\n",
    "print('generated data:',new_X.shape)\n",
    "print(lda.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于特征值的非线性降维方法（流型学习）：\n",
    "### LLE 局部线性嵌入\n",
    "局部线性嵌入(Locally Linear Embedding，以下简称LLE)，也是流形学习算法，LLE关注于降维时保持样本局部的线性关系，由于LLE在降维时保持了样本的局部关系，它广泛的用于图像图像识别，高维数据可视化等领域。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete\n",
    "\n",
    "from sklearn import manifold\n",
    "#se = manifold.SpectralEmbedding(n_components=num_of_col, n_neighbors=10)\n",
    "#Y = se.fit_transform(X)\n",
    "new_X, err = manifold.locally_linear_embedding(X, n_neighbors=12,\n",
    "                                             n_components=num_of_col)\n",
    "print(\"Done. Reconstruction error: %g\" % err)\n",
    "\n",
    "new_df=pd.DataFrame(np.c_[new_X,Y],columns=col_name)\n",
    "writer = pd.ExcelWriter(os.path.join(drd_path,'data_LLE.xlsx'))\n",
    "new_df.to_excel(writer,'Sheet1',index=False)\n",
    "writer.save()\n",
    "print('generated data:',new_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-SNE\n",
    "n_components应该小于4，因为它依赖于四叉树或oct树。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated data: (4141, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE \n",
    "cols=3 if num_of_col>3 else num_of_col\n",
    "new_X = TSNE(n_components=cols, n_iter=300).fit_transform(X)\n",
    "\n",
    "new_df=pd.DataFrame(np.c_[new_X,Y],columns=col_name)\n",
    "writer = pd.ExcelWriter(os.path.join(drd_path,'data_tSNE.xlsx'))\n",
    "new_df.to_excel(writer,'Sheet1',index=False)\n",
    "writer.save()\n",
    "print('generated data:',new_X.shape)\n",
    "\n",
    "if num_of_col<=3:\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.title('t-SNE components')\n",
    "    tsne=new_X\n",
    "    for i in range(num_of_col):\n",
    "        plt.scatter(tsne[:,i], tsne[:,(i+1)%num_of_col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ISOMAP流形学习\n",
    "流形学习是非线性降维的主要方法，是MDS在流形学习上的扩展，将非欧几里德空间转换从欧几里德空间\n",
    "\n",
    "使用的参数：\n",
    "\n",
    "n_neighbors：决定每个点的相邻点数\n",
    "\n",
    "n_components：决定流形的坐标数\n",
    "\n",
    "n_jobs = -1：使用所有可用的CPU核心"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated data: (4141, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import Isomap\n",
    "new_X= Isomap(n_neighbors=5, n_components=num_of_col, n_jobs=-1).fit_transform(X)\n",
    "\n",
    "new_df=pd.DataFrame(np.c_[new_X,Y],columns=col_name)\n",
    "writer = pd.ExcelWriter(os.path.join(drd_path,'data_ISOMAP.xlsx'))\n",
    "new_df.to_excel(writer,'Sheet1',index=False)\n",
    "writer.save()\n",
    "print('generated data:',new_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MDS降维（多维标度法）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated data: (4141, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import MDS\n",
    "mds = MDS( n_components=num_of_col, metric=True)\n",
    "new_X = mds.fit_transform(X)\n",
    "\n",
    "new_df=pd.DataFrame(np.c_[new_X,Y],columns=col_name)\n",
    "writer = pd.ExcelWriter(os.path.join(drd_path,'data_MDS.xlsx'))\n",
    "new_df.to_excel(writer,'Sheet1',index=False)\n",
    "writer.save()\n",
    "print('generated data:',new_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 无监督：\n",
    "### 独立成分分析法（ICA）\n",
    "是基于信息理论的一种常用的降维方法，其与PCA主要的不同是PCA是寻找不相关的变量，而ICA是挑选独立变量。如果两个变量不相关，它们之间就没有线性关系。如果它们是独立的，它们就不依赖于其他变量。同时PCA主要对于高斯分布数据比较有效，而ICA适用于其他分布。我们可以调用sklearn中的FastICA函数来进行数据独立成分分析。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated data: (4141, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import FastICA\n",
    "#独立分量分析（ICA）PCA和ICA之间的主要区别在于，PCA寻找不相关的因素，而ICA寻找独立因素。\n",
    "ICA = FastICA(n_components=num_of_col, random_state=12)\n",
    "new_X = ICA.fit_transform(X)\n",
    "\n",
    "new_df=pd.DataFrame(np.c_[new_X,Y],columns=col_name)\n",
    "writer = pd.ExcelWriter(os.path.join(drd_path,'data_ICA.xlsx'))\n",
    "new_df.to_excel(writer,'Sheet1',index=False)\n",
    "writer.save()\n",
    "print('generated data:',new_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LE 拉普拉斯特征映射"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import SpectralEmbedding\n",
    "se = SpectralEmbedding(n_components=num_of_col, n_neighbors=10)\n",
    "new_X = se.fit_transform(X)\n",
    "new_df=pd.DataFrame(np.c_[new_X,Y],columns=col_name)\n",
    "writer = pd.ExcelWriter(os.path.join(drd_path,'data_LE.xlsx'))\n",
    "new_df.to_excel(writer,'Sheet1',index=False)\n",
    "writer.save()\n",
    "print('generated data:',new_X.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
